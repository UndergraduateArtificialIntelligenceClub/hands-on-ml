
\documentclass[xcolor=dvipsnames, fontsize=11pt, % Font size
pagesize, % Write page size to dvi or pdf
parskip=half-, t]{beamer}

\input{beamer.tex}
\usepackage{multicol}
%\titlegraphic{\includegraphics[height=0.15\textwidth]{../logo.png}}
\title[Artificial Intelligence for Beginners]{Gradient Descent}
\subtitle{Towards Neural Networks}
\author[Justin Stevens]{\large Justin Stevens} % Your name
\date{}
\setbeamertemplate{button}{\tikz
	\node[
	inner xsep=10pt,
	draw=structure!80,
	fill=structure!50,
	rounded corners=4pt]  {\large\insertbuttontext};}
\usepackage{asymptote}
\usepackage{animate}
\usepackage{xmpmulti}
\begin{document}
	\renewcommand{\thefootnote}{\fnsymbol{footnote}}
	\begin{frame}[c]
	\centering
	\titlepage
\end{frame}
\section{Decision Making}
\subsection{Perceptrons}
\begin{frame}{Should I Stay or Should I Go?}
Let's say I'm deciding on a given day whether or not to go to  an Edmonton Oilers game. Here are the factors that will influence my decision: \pause 
\begin{itemize}
\item Are the tickets cheap or expensive?
\item Do I have the time to go?
\item Do I care about the team they're playing?
\end{itemize} \pause 
We'll make my decision by encoding each possible input as a vector $\bar{x}$: \pause
\begin{table} \center 
\begin{tabular}{ccc|c}
Ticket Prices & Availability & Interest & $\bar{x}$\\ \hline 
Cheap & Yes & Yes & $(1,1,1)$ \\
Cheap & No & No & $(1,0,0)$ \\
Cheap & Yes & No & $(1,1,0)$ \\
Cheap & No & Yes & $(1,0,1)$  \\
Expensive & Yes & Yes & $(0,1,1)$ \\
Expensive & No & No & $(0,0,0)$ \\
Expensive & No & Yes & $(0,0,1)$ \\
Expensive & Yes & No & $(0,1,0)$ 
\end{tabular}
\end{table}
\end{frame}

\begin{frame}{How Will I Make my Decision?}
Let's say I don't care much about price, but I do care about my availability and interest. In this case, the corresponding weights might be $\bar{w}=(1, 6, 3)$. \pause We can then compute the dot product $\bar{w}\cdot \bar{x}$ for each possible input:  \pause 
\begin{table} 
\center 
\begin{tabular}{cccc|c}
Ticket Prices & Availability & Interest & $\bar{x}$ & $\bar{w}\cdot \bar{x}$ \\ \hline 
Cheap & Yes & Yes & $(1,1,1)$ & $10$ \\
Cheap & No & No & $(1,0,0)$ & $1$ \\
Cheap & Yes & No & $(1,1,0)$ & $7$\\
Cheap & No & Yes & $(1,0,1)$ & $4$   \\
Expensive & Yes & Yes & $(0,1,1)$ & $9$ \\
Expensive & No & No & $(0,0,0)$  & $0$ \\
Expensive & No & Yes & $(0,0,1)$ & $3$\\
Expensive & Yes & No & $(0,1,0)$ & $6$
\end{tabular}
\end{table} \pause
\vspace{0.05\textheight}
We can now define my \textbf{activation threshold}, $t$, which will determine whether or not I go to the game, represented in binary.
\end{frame}

\begin{frame}{Formula for Decision Making}
The general formula for my decision to go to the Oilers game is $$\text{output}=\begin{cases} 0 & \text{ if } \bar{w}\cdot \bar{x}<t \\ 
1 & \text{ if } \bar{w}\cdot \bar{x}\ge t. \end{cases}$$ \pause 
For instance, if $t=9$, we see I'll only go if I'm both available and interested. \pause If $t=7$, I'll also go if the tickets are cheap and I'm available:
\begin{table} 
\center 
\begin{tabular}{cccc|c}
Ticket Prices & Availability & Interest & $\bar{x}$ & $\bar{x}\cdot \bar{w}$ \\ \hline 
\textbf{\textcolor{Green}{Cheap}} & \textbf{\textcolor{Green}{Yes}} & \textbf{\textcolor{Green}{Yes}} & $(1,1,1)$ & \textbf{\textcolor{Green}{10}} \\
Cheap & No & No & $(1,0,0)$ & $1$ \\
\textbf{\textcolor{Green}{Cheap }}& \textbf{\textcolor{Green}{Yes }}& \textbf{\textcolor{Green}{No}} & $(1,1,0)$ & \textbf{\textcolor{Green}{7}} \\
Cheap & No & Yes & $(1,0,1)$ & $4$   \\
\textbf{\textcolor{Green}{Expensive}} & \textbf{\textcolor{Green}{Yes}} & \textbf{\textcolor{Green}{Yes}} & $(0,1,1)$ & \textbf{\textcolor{Green}{9}} \\
Expensive & No & No & $(0,0,0)$  & $0$ \\
Expensive & No & Yes & $(0,0,1)$ & $3$\\
Expensive & Yes & No & $(0,1,0)$ & $6$
\end{tabular}
\end{table}
\end{frame}
\begin{frame}{Perceptrons}
This is a simplified model of a \textbf{perceptron}. The idea was developed by Frank Rosenblatt at Cornell in 1957, and is often used in psychology. \pause 

\begin{figure}
\center
\includegraphics[scale=0.75]{perc.png}
\end{figure} \pause
\vspace{0.05\textheight} 
Each of these lines collect evidence and are weighted to produce an output. \pause In practice, our inputs and outputs don't necessarily have to be binary; they can be real-valued. We therefore have to define a new activation function. \pause First, we have to make a slight modification to our model.
\end{frame}
\subsection{Activation Functions}
\begin{frame}{Introducing the Bias}
Instead of comparing our weighted sum to a threshold, we instead \textit{add} a bias, $b$, to our weighted sum. \pause We write this as $\bar{w}\cdot \bar{x}+b$ instead. \pause Then $$\text{output}=\begin{cases} 0 & \text{ if } \bar{w}\cdot \bar{x}+b<0 \\ 
1 & \text{ if } \bar{w}\cdot \bar{x}+b\ge 0. \end{cases}$$ \pause
Sometimes we'll need to calculate a value as an intermediate step in a calculation. In this case, we use various \textbf{activation functions}. \pause The one presented above is known as the \textit{heaviside step function}. There's also the \textbf{rectified linear unit}, which is defined by $f(x)=\text{max}\{0, x\}$. \pause Graphically,
\begin{figure}
\includegraphics[scale=0.42]{rectifier.png}
\caption{Rectifier, and a smooth approximation $\log(1+e^x)$. (\textit{Source: Wikipedia}).}
\end{figure}

\end{frame}





\section{Classifying Digits through MNIST}
\subsection{Defining the Problem}
\begin{frame}[c]{Example Images}
\begin{figure} 
\center
\includegraphics{mnist_100_digits.png}
\caption{How would you devise a system for a \textbf{computer} to classify the digits? What assumptions do we have to make about the data set, known as MNIST? }
\end{figure}
\end{frame}

\begin{frame}[c]{Assumptions}
\begin{itemize}
\item The MNIST database contains thousands of handwritten digits.  \pause 
\item Each data-point contains both an image, and the desired digit. \pause 
\item Each image contains pixels ranging $0$ to $255$, with $8$ bits used. 
\item  An individual image is a $28\times 28$ array of pixels.\pause  
\item The desired digit is represented as a number from $0$ to $9$. \pause 
\item $60,000$ images are designated for training, and $10,000$ for testing. \pause 
\item We'll build a model from the training images that will learn to classify digits!
\end{itemize}
\end{frame}

\begin{frame}{What we're building towards}
\begin{figure}
\center
\includegraphics[scale=0.36]{goal.png}
\caption{A simple neural network structure. The input vectors on the left hand side have $28\times 28=784$ inputs for each pixel, and the output layer has $10$ digits, one for each number from $0$ to $9$.}
\end{figure}
\end{frame}



\subsection{References}
\begin{frame}[c]{References}
\setbeamertemplate{itemize items}[triangle]

\href{http://www.slader.com/textbook/9780495011668-stewart-calculus-early-transcendentals-6th-edition/}{\beamergotobutton{Stewart Calculus: Early Transcedentals, 6th Edition}} \smallskip

\href{https://www.youtube.com/playlist?list=PLDesaqWTN6ESk16YRmzuJ8f6-rnuy0Ry7}{\beamergotobutton{Professor Leonard Calculus 3 (Full Length Videos)}} \smallskip

\href{http://tutorial.math.lamar.edu/Classes/CalcIII/CalcIII.aspx}{\beamergotobutton{Paul's Online Math Notes, Calculus III}} 
\end{frame}
\end{document}